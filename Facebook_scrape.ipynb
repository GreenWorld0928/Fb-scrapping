{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb1a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium-related\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b7a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other necessary ones\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029767c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import customtkinter as ctk \n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5091b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacebookScraper:\n",
    "    def __init__(self):\n",
    "        #self.option = option\n",
    "        self.option = Options()\n",
    "        self.option.add_argument('--headless')\n",
    "        self.option.add_argument('--no-sandbox')\n",
    "        self.option.add_argument(\"--disable-dev-shm-usage\")\n",
    "        self.option.add_argument(\"--disable-infobars\")\n",
    "        self.option.add_argument(\"start-maximized\")\n",
    "        self.option.add_argument(\"--disable-extensions\")\n",
    "        #self.browser = browser\n",
    "        self.browser = webdriver.Chrome(executable_path=\":~/Scrapers/FacebookGUI/webdriver/chromedriver-linux64/chromedriver\", options=self.option)\n",
    "        self.scroll_page = self.browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        \n",
    "        # X-paths\n",
    "        # x-path to main article containing each comment\n",
    "        self.article_class = 'by bz ca'\n",
    "        self.article_id = 'u_0_'\n",
    "        \n",
    "        # footer class xpath under article holding comments, React, Share\n",
    "        self.footer = 'cx'\n",
    "        \n",
    "        # span class xpath to obtain comments storylink\n",
    "        self.story_href= 'l cy'\n",
    "        \n",
    "        # once storylink is clicked the div class xpath to each commnet\n",
    "        self.comments_class = 'ek'\n",
    "        \n",
    "        # nameid of the one commenting a class xpath under h3 \n",
    "        self.name_id = 'el bs'\n",
    "        # div class xpath to the comment\n",
    "        self.raw_comment = 'em'\n",
    "        \n",
    "        \n",
    "        \n",
    "    # login function\n",
    "    def login(self, email,password):\n",
    "        # facebook basic -- choosen for it's simplicity\n",
    "        self.browser.get(\"https://mbasic.facebook.com/\")\n",
    "        self.browser.maximize_window()\n",
    "        wait = WebDriverWait(self.browser, 30)\n",
    "        # login \n",
    "        email_field = wait.until(EC.visibility_of_element_located((By.NAME, 'email')))\n",
    "        email_field.send_keys(email)\n",
    "        pass_field = wait.until(EC.visibility_of_element_located((By.NAME, 'pass')))\n",
    "        pass_field.send_keys(password)\n",
    "        pass_field.send_keys(Keys.RETURN) \n",
    "    \n",
    "    # function to obtain pages links\n",
    "    def get_page(self,query):\n",
    "        self.browser.get(f'https://mbasic.facebook.com/search/pages/?q={query}')\n",
    "        src = self.browser.page_source\n",
    "        # list to store hrefs links  \n",
    "        hrefs = []\n",
    "        # parser by beautiful soup\n",
    "        soup=bs(src,'html.parser') \n",
    "        for s in soup.find_all('a'):\n",
    "            href = s.get('href')\n",
    "            hrefs.append(href)\n",
    "        prof_links = []\n",
    "        for hfs in hrefs:\n",
    "            for h in hfs.split(\" \"):\n",
    "                if \"offic\" in h:\n",
    "                    prof_links.append(h)\n",
    "        return prof_links\n",
    "        \n",
    "    \n",
    "    # function to obtain the /storyid/ \n",
    "    def get_storylink(self):\n",
    "        # footer xpath\n",
    "        self.scroll_page\n",
    "        footer = self.browser.find_elements_by_xpath(f\"//footer[@class='{self.footer}']\")\n",
    "        # list to store links\n",
    "        links_sum = []\n",
    "        for foot in footer:\n",
    "            # comment link xpath\n",
    "            com_links = foot.find_elements_by_xpath(f\"//div[@class='{self.story_href}']\")\n",
    "            for com_link in com_links:\n",
    "                # storyid href xpath\n",
    "                # get all that contains story\n",
    "                elem = com_link.find_element_by_xpath(\"//a[contains(@href,'/story.php?')]\")\n",
    "                story_link = elem.get_attribute('href')\n",
    "                links_sum.append(story_link)\n",
    "        # yield story links\n",
    "        return links_sum\n",
    "    # scroll page function\n",
    "    #def story(self):\n",
    "         #scroll the page\n",
    "    #    return self.browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "    ## gets comment links\n",
    "    def navigate(self, prof_link):\n",
    "        #print(\"Navigating...\")\n",
    "        # prioritize for the first one\n",
    "        prof_ck = self.browser.find_element_by_xpath(f\"//a[@href='{prof_link[0]}']\").click()\n",
    "        \n",
    "        # sleep \n",
    "        time.sleep(5)\n",
    "    \n",
    "        # click on Timeline\n",
    "        element = self.browser.find_element_by_xpath(\"//a[contains(text(), 'Timeline')]\").click()\n",
    "    \n",
    "        # sleep\n",
    "        time.sleep(5)\n",
    "    \n",
    "        # scroll\n",
    "        self.scroll_page\n",
    "    \n",
    "        # sleep\n",
    "        time.sleep(1)\n",
    "    \n",
    "        # see more stories click \n",
    "        element2 = self.browser.find_element_by_xpath(\"//span[contains(text(), 'See more stories')]\").click()\n",
    "    \n",
    "        # sleep\n",
    "        time.sleep(5)\n",
    "        # scroll\n",
    "        self.scroll_page\n",
    "        #self.browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # get comments\n",
    "        \n",
    "    def all_comments(self):\n",
    "        self.scroll_page\n",
    "        time.sleep(5)\n",
    "        src = self.browser.page_source\n",
    "        # list to store hrefs links  \n",
    "        hrefs = []\n",
    "        # parser by beautiful soup\n",
    "        soup=bs(src,'html.parser') \n",
    "        for s in soup.find_all('a'):\n",
    "            href = s.get('href')\n",
    "            hrefs.append(href)\n",
    "        stry_links = []\n",
    "        for hfs in hrefs:\n",
    "            for h in hfs.split(\" \"):\n",
    "                if \"/story.php?\" in h:\n",
    "                    stry_links.append(h)\n",
    "        return set(stry_links)\n",
    "        \n",
    "    # get comments, name, url\n",
    "    def get_comments_links(self,stry_link):\n",
    "        # dictionary to name of one who commented, url to the post, comment\n",
    "        comments = {}\n",
    "        c_h = stry_link.encode(encoding = 'UTF-8')\n",
    "        c_h = repr(c_h)[2:-1]\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # click the story\n",
    "        self.browser.get(f\"{str(c_h)}\")\n",
    "        \n",
    "        # sleep\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # scroll\n",
    "     \n",
    "        self.scroll_page\n",
    "        time.sleep(5)\n",
    "        #comms = self.browser.find_elements_by_xpath(f\"//div[@class='{self.comments_class}']\")\n",
    "#         # get all from comments class\n",
    "#         comms = self.browser.find_elements(By.CLASS_NAME,f\"{self.comments_class}\")\n",
    "#         for com in comms:\n",
    "        self.scroll_page\n",
    "        IDs = self.browser.find_elements_by_xpath(\"//*[contains(@id, '0') or contains(@id, '1') or contains(@id, '2') or contains(@id, '3') or contains(@id, '4') or contains(@id, '5') or contains(@id, '6') or contains(@id, '7') or contains(@id, '8') or contains(@id, '9')]\")\n",
    "        pattern = r'^[0-9]{15,16}$'\n",
    "        for ID in IDs:\n",
    "            ID_at = ID.get_attribute(\"id\")\n",
    "            # Use re.findall to find all matching strings\n",
    "            com_ids = [Id for Id in ID_at if re.search(pattern, ID_at)]\n",
    "            coms_id = ''.join(com_ids)\n",
    "            time.sleep(5)\n",
    "            #h3 = Id.find_element(By.TAG_NAME,'div')\n",
    "            if coms_id != \"\":\n",
    "                comment = self.browser.find_element_by_xpath(f\"//*[@id='{coms_id}']/div/div[1]\").text\n",
    "                name_id = self.browser.find_element_by_xpath(f\"//*[@id='{coms_id}']/div/h3/a\").text\n",
    "                #print(\"**name\", name_id)\n",
    "                #print(\"***comment\", comment)\n",
    "                #print(\"*** Name \",name_id)\n",
    "                #comments['Name'] = name_id\n",
    "                #comments['Url'] = stry_link\n",
    "                #comments['Comment'] = comment\n",
    "                return stry_link, name_id, comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6c0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GUI(FacebookScraper):\n",
    "    def __init__(self, ctk):\n",
    "        super().__init__()\n",
    "        self.ctk = ctk\n",
    "        self.app = ctk.CTk()\n",
    "        self.new = ctk.CTk()\n",
    "    \n",
    "    def results(self):\n",
    "        email = self.Email_ent.get()\n",
    "        passw = self.passw_ent.get()\n",
    "        query = self.query_ent.get()\n",
    "        \n",
    "        try:\n",
    "            # login\n",
    "            self.login(email,passw)\n",
    "            self.display.configure(state=self.ctk.NORMAL)\n",
    "            self.display.insert(self.ctk.END, \"Logging In....\")\n",
    "            self.display.configure(state=self.ctk.DISABLED)\n",
    "            # sleep\n",
    "            time.sleep(5)\n",
    "            # navigate to desired query and obtain the posts\n",
    "            prof_link = self.get_page(query)\n",
    "            self.navigate(prof_link)\n",
    "            self.display.configure(state=self.ctk.NORMAL)\n",
    "            self.display.insert(self.ctk.END, \"Navigating....\")\n",
    "            self.display.configure(state=self.ctk.DISABLED)\n",
    "            story_links = []\n",
    "            time.sleep(5)\n",
    "            comz = self.all_comments()\n",
    "            for coms in comz:\n",
    "                story_links.append(\"https://mbasic.facebook.com\"+coms)\n",
    "            \n",
    "            all_comments = {}\n",
    "            self.display.configure(state=self.ctk.NORMAL)\n",
    "            self.display.insert(self.ctk.END, \"Getting Comments\")\n",
    "            self.display.configure(state=self.ctk.DISABLED)\n",
    "        #   # iterate through story_links\n",
    "            for story in story_links:\n",
    "                url, name, comment = self.get_comments_links(story)\n",
    "                #all_comments['URL: '] = url\n",
    "                #all_comments['Commentor: '] = name\n",
    "                #all_comments['Comment: '] = comment\n",
    "                self.display.configure(state=self.ctk.NORMAL)\n",
    "                self.display.insert(self.ctk.END, f\"URL: {url} Commentor: {name} Comment: {comment} \\n\")\n",
    "                self.display.configure(state=self.ctk.DISABLED)\n",
    "        except:\n",
    "            self.display.configure(state=self.ctk.NORMAL)\n",
    "            self.display.insert(self.ctk.END, \"Sorry seems there was a problem \\n 1. Try to login to the account normally before scraping \\n 2. Check internet connection \\n\")\n",
    "            self.display.configure(state=self.ctk.DISABLED)\n",
    " \n",
    "       \n",
    "    def wind(self):\n",
    "        # create a window\n",
    "        #app = ctk.CTk()\n",
    "        self.app.title(\"Facebook Scraper\")\n",
    "        self.app.geometry(\"350x300\")\n",
    "        self.app.config(bg=\"#242320\")\n",
    "\n",
    "        font1 = ('Arial', 18, 'bold')\n",
    "\n",
    "        # inputs labels\n",
    "        Email_label = self.ctk.CTkLabel(self.app, text=\"Email \", text_color=\"#000000\", font=self.ctk.CTkFont(font1))\n",
    "        Email_label.place(x=5, y=25)\n",
    "        passw_label = self.ctk.CTkLabel(self.app, text=\"Password \", text_color=\"#000000\", font=self.ctk.CTkFont(font1))\n",
    "        passw_label.place(x=5, y=55)\n",
    "        query_label = self.ctk.CTkLabel(self.app, text=\"Query \", text_color=\"#000000\", font=self.ctk.CTkFont(font1))\n",
    "        query_label.place(x=5, y=85)\n",
    "\n",
    "        self.Email_ent = self.ctk.CTkEntry(self.app, fg_color=\"#FFFFFF\", text_color=\"#000000\", border_color=\"#FFFFFF\", width=200, height=1)\n",
    "        self.Email_ent.place(x=130, y=25)\n",
    "        self.passw_ent = self.ctk.CTkEntry(self.app,show=\"*\", fg_color=\"#FFFFFF\", text_color=\"#000000\", border_color=\"#FFFFFF\", width=200, height=1)\n",
    "        self.passw_ent.place(x=130, y=55)\n",
    "        self.query_ent = self.ctk.CTkEntry(self.app, fg_color=\"#FFFFFF\", text_color=\"#000000\", border_color=\"#FFFFFF\", width=200, height=1)\n",
    "        self.query_ent.place(x=130, y=85)\n",
    "\n",
    "        self.login_but = self.ctk.CTkButton(self.app, text=\"Scrape\",command=self.results, text_color=\"#FFFFFF\", fg_color=\"#07b527\", hover_color=\"#07b527\")\n",
    "        self.login_but.place(x=140, y=120)\n",
    "\n",
    "        self.display = self.ctk.CTkTextbox(self.app, width=310, height=140, state=ctk.DISABLED)\n",
    "        self.display.place(x=20, y=150)\n",
    "        \n",
    "        self.app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f2497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    g = GUI(ctk)\n",
    "    g.wind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5a6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
